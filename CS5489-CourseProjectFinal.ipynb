{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS5489 - Course Project - Final\n",
    "\n",
    "Due date: May 4, 11:59pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "For the course project, select one of the following competitions on Kaggle:\n",
    "\n",
    "### [Plant Pathology 2020 - FGVC7](https://www.kaggle.com/c/plant-pathology-2020-fgvc7/overview): Identify the category of foliar diseases in apple trees\n",
    "\n",
    "> Misdiagnosis of the many diseases impacting agricultural crops can lead to misuse of chemicals leading to the emergence of resistant pathogen strains, increased input costs, and more outbreaks with significant economic loss and environmental impacts. Current disease diagnosis based on human scouting is time-consuming and expensive, and although computer-vision based models have the promise to increase efficiency, the great variance in symptoms due to age of infected tissues, genetic variations, and light conditions within trees decreases the accuracy of detection.\n",
    ">\n",
    "> Objectives of ‘Plant Pathology Challenge’ are to train a model using images of training dataset to 1) Accurately classify a given image from testing dataset into different diseased category or a healthy leaf; 2) Accurately distinguish between many diseases, sometimes more than one on a single leaf; 3) Deal with rare classes and novel symptoms; 4) Address depth perception—angle, light, shade, physiological age of the leaf; and 5) Incorporate expert knowledge in identification, annotation, quantification, and guiding computer vision to search for relevant features during learning.\n",
    "\n",
    "### [University of Liverpool - Ion Switching](https://www.kaggle.com/c/liverpool-ion-switching/overview): Identify the number of channels open at each time point\n",
    "\n",
    ">Think you can use your data science skills to make big predictions at a submicroscopic level?\n",
    ">\n",
    ">Many diseases, including cancer, are believed to have a contributing factor in common. Ion channels are pore-forming proteins present in animals and plants. They encode learning and memory, help fight infections, enable pain signals, and stimulate muscle contraction. If scientists could better study ion channels, which may be possible with the aid of machine learning, it could have a far-reaching impact.\n",
    ">\n",
    ">When ion channels open, they pass electric currents. Existing methods of detecting these state changes are slow and laborious. Humans must supervise the analysis, which imparts considerable bias, in addition to being tedious. These difficulties limit the volume of ion channel current analysis that can be used in research. Scientists hope that technology could enable rapid automatic detection of ion channel current events in raw data.\n",
    ">\n",
    ">The University of Liverpool’s Institute of Ageing and Chronic Disease is working to advance ion channel research. Their team of scientists have asked for your help. In this competition, you’ll use ion channel data to better model automatic identification methods. If successful, you’ll be able to detect individual ion channel events in noisy raw signals. The data is simulated and injected with real world noise to emulate what scientists observe in laboratory experiments.\n",
    ">\n",
    ">Technology to analyze electrical data in cells has not changed significantly over the past 20 years. If we better understand ion channel activity, the research could impact many areas related to cell health and migration. From human diseases to how climate change affects plants, faster detection of ion channels could greatly accelerate solutions to major world problems.\n",
    "\n",
    "### [Jigsaw Multilingual Toxic Comment Classification](https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification): Use TPUs to identify toxicity comments across multiple languages\n",
    "\n",
    ">It only takes one toxic comment to sour an online discussion. The Conversation AI team, a research initiative founded by Jigsaw and Google, builds technology to protect voices in conversation. A main area of focus is machine learning models that can identify toxicity in online conversations, where toxicity is defined as anything rude, disrespectful or otherwise likely to make someone leave a discussion. If these toxic contributions can be identified, we could have a safer, more collaborative internet.\n",
    ">\n",
    ">In the previous 2018 Toxic Comment Classification Challenge, Kagglers built multi-headed models to recognize toxicity and several subtypes of toxicity. In 2019, in the Unintended Bias in Toxicity Classification Challenge, you worked to build toxicity models that operate fairly across a diverse range of conversations. This year, we're taking advantage of Kaggle's new TPU support and challenging you to build multilingual models with English-only training data.\n",
    ">\n",
    ">Jigsaw's API, Perspective, serves toxicity models and others in a growing set of languages (see our documentation for the full list). Over the past year, the field has seen impressive multilingual capabilities from the latest model innovations, including few- and zero-shot learning. We're excited to learn whether these results \"translate\" (pun intended!) to toxicity classification. Your training data will be the English data provided for our previous two competitions and your test data will be Wikipedia talk page comments in several different languages.\n",
    ">\n",
    ">As our computing resources and modeling capabilities grow, so does our potential to support healthy conversations across the globe. Develop strategies to build effective multilingual models and you'll help Conversation AI and the entire industry realize that potential.\n",
    "\n",
    "\n",
    "## Groups\n",
    "Group projects should contain 2 students.  To sign up for a group, go to Canvas and under \"People\", join one of the existing \"Project Groups\".  _For group projects, the project report must state the percentage contribution from each project member._\n",
    "\n",
    "## Methodology\n",
    "You are free to choose the methodology to solve the task.  In machine learning, it is important to use domain knowledge to help solve the problem.  Hence, instead of blindly applying the algorithms to the data you need to think about how to represent the data in a way that makes sense for the algorithm to solve the task. \n",
    "\n",
    "\n",
    "## Evaluation on Kaggle\n",
    "\n",
    "The final evaluation will be performed on Kaggle.\n",
    "\n",
    "## Project Presentation\n",
    "\n",
    "Each project group needs to give a presentation at the end of the semester.  The presentation time is 8 minutes.  You _must_ give a presentation.\n",
    "\n",
    "## What to hand in\n",
    "\n",
    "You need to turn in the following things:\n",
    "\n",
    "1. This ipynb file `CourseProject-2020.ipynb` with your source code and documentation. You should write about all the various attempts that you make to find a good solution.\n",
    "2. Your final submission file to Kaggle.\n",
    "3. The ipynb file `CourseProject-2018-final.ipynb`, which contains the code that generates the final submission file that you submit to Kaggle. This code will be used to verify that your Kaggle submission is reproducible.\n",
    "4. Presentation slides.\n",
    "\n",
    "Files should be uploaded to \"Course Project\" on Canvas.\n",
    "\n",
    "\n",
    "## Grading\n",
    "The marks of the assignment are distributed as follows:\n",
    "- 40% - Results using various feature representations, dimensionality reduction methods, classifiers, etc.\n",
    "- 25% - Trying out feature representations (e.g. adding additional features, combining features from different sources) or methods not used in the tutorials.\n",
    "- 15% - Quality of the written report.  More points for insightful observations and analysis.\n",
    "- 15% - Project presentation\n",
    "- 5% - Final ranking on the Kaggle test data (private leaderboard).\n",
    "\n",
    "**Late Penalty:** 25 marks will be subtracted for each day late.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUR METHODS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "\n",
    "from sklearn import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Conv2D, Flatten, Input, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import backend as K\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# tqdm.pandas()\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import plotly.offline as pyo\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "pyo.init_notebook_mode()\n",
    "from keras.utils import plot_model\n",
    "\n",
    "np.random.seed(2020)\n",
    "# tf.random.set_seed(2020)\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "print(f'Tensorflow version: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "IMAGE_PATH = \"./dataset/images/\"\n",
    "TEST_PATH = \"./dataset/test.csv\"\n",
    "TRAIN_PATH = \"./dataset/train.csv\"\n",
    "SUB_PATH = \"./dataset/sample_submission.csv\"\n",
    "\n",
    "if os.path.exists(\"/kaggle/input/plant-pathology-2020-fgvc7/images\"):\n",
    "    IMAGE_PATH = \"/kaggle/input/plant-pathology-2020-fgvc7/images/\"\n",
    "    TEST_PATH = \"/kaggle/input/plant-pathology-2020-fgvc7/test.csv\"\n",
    "    TRAIN_PATH = \"/kaggle/input/plant-pathology-2020-fgvc7/train.csv\"\n",
    "    SUB_PATH = \"/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv\"\n",
    "\n",
    "sub = pd.read_csv(SUB_PATH)\n",
    "test_data = pd.read_csv(TEST_PATH)\n",
    "train_data = pd.read_csv(TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(train_data))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(test_data))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_path(image_id, basedir=IMAGE_PATH):\n",
    "    return basedir + image_id + '.jpg'\n",
    "\n",
    "test_paths = test_data.image_id.apply(format_path).values\n",
    "train_paths = train_data.image_id.apply(format_path).values\n",
    "\n",
    "train_labels = np.float32(train_data.loc[:, 'healthy':'scab'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_paths))\n",
    "print(len(test_paths))\n",
    "print(train_paths[0])\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize sample leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['healthy', 'multiple_diseases', 'rust', 'scab']\n",
    "def get_tages(labels):\n",
    "    tags = []\n",
    "    for label in labels:\n",
    "        tag = [classes[i] for i in range(4) if label[i] == 1]\n",
    "        tags.append(tag)\n",
    "    return tags\n",
    "\n",
    "train_tags = get_tages(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(file_path):\n",
    "    image = cv2.imread(file_path)\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def show_samples(c='healthy'):\n",
    "    plt.figure(figsize=(16,10))\n",
    "    num = 0\n",
    "    for i in range(len(train_paths)):\n",
    "        if c not in train_tags[i]:\n",
    "            continue\n",
    "        plt.subplot(4, 4, num+1)\n",
    "        plt.imshow(cv2.resize(load_image(train_paths[i]), (205, 136))) \n",
    "        plt.title(' '.join(train_tags[i]))\n",
    "        plt.axis('off')\n",
    "        num += 1\n",
    "        if num == 16:\n",
    "            break\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split training and valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training and valid dataset\n",
    "train_paths, valid_paths, train_labels, valid_labels = \\\n",
    "    train_test_split(train_paths, train_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-processing data for generative classifiers and discriminative classifiers\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pre-processing data for DNN\n",
    "\n",
    "In the next sections we use deep neural networks to fit the dataset.\n",
    "\n",
    "In this section we build a set of data preprocessing pipelines including data augmentation, tensorflow dataset generation and lazy loading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image augmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build input pipeline\n",
    "\n",
    "In this section we build the pipeline that assembles the steps of model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(filename, label=None, image_size=(512, 512)):\n",
    "    bits = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(bits, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    \n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label\n",
    "\n",
    "def data_augment(image, label=None):\n",
    "    # add different data augmentation methods here\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.5)\n",
    "    image = tf.image.random_saturation(image, 0.5, 3)\n",
    "    image = tf.image.random_contrast(image, 0.5, 3)\n",
    "    \n",
    "    if label is None:\n",
    "        return image\n",
    "    else:\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "# BATCH_SIZE = 8  # \n",
    "# STEPS_PER_EPOCH = train_labels.shape[0] // BATCH_SIZE\n",
    "\n",
    "\n",
    "def build_dataset(batch_size, data_augment,\n",
    "                 train_paths=train_paths,\n",
    "                 train_labels=train_labels,\n",
    "                 valid_paths=valid_paths,\n",
    "                 valid_labels=valid_labels,\n",
    "                 test_paths=test_paths):\n",
    "    if data_augment:\n",
    "        print('Data augment enabled.')\n",
    "        train = (\n",
    "            tf.data.Dataset\n",
    "            .from_tensor_slices((train_paths, train_labels))\n",
    "            .map(decode_image, num_parallel_calls=AUTOTUNE)\n",
    "            .map(data_augment, num_parallel_calls=AUTOTUNE)\n",
    "            .repeat()\n",
    "            .shuffle(512)\n",
    "            .batch(batch_size)\n",
    "            .prefetch(AUTOTUNE)\n",
    "        )\n",
    "    else:\n",
    "        train = (\n",
    "            tf.data.Dataset\n",
    "            .from_tensor_slices((train_paths, train_labels))\n",
    "            .map(decode_image, num_parallel_calls=AUTOTUNE)\n",
    "            .repeat()\n",
    "            .shuffle(512)\n",
    "            .batch(batch_size)\n",
    "            .prefetch(AUTOTUNE)\n",
    "        )\n",
    "\n",
    "\n",
    "    valid = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices((valid_paths, valid_labels))\n",
    "        .map(decode_image, num_parallel_calls=AUTOTUNE)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    test = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices(test_paths)\n",
    "        .map(decode_image, num_parallel_calls=AUTOTUNE)\n",
    "        .batch(batch_size)\n",
    "    )\n",
    "    \n",
    "    return train, valid, test\n",
    "\n",
    "# train_dataset, valid_dataset, test_dataset = build_dataset(BATCH_SIZE, None)\n",
    "\n",
    "#     train_dataset = (\n",
    "#         tf.data.Dataset\n",
    "#         .from_tensor_slices((train_paths, train_labels))\n",
    "#         .map(decode_image, num_parallel_calls=AUTOTUNE)\n",
    "#         .map(data_augment, num_parallel_calls=AUTOTUNE)\n",
    "#         .repeat()\n",
    "#         .shuffle(512)\n",
    "#         .batch(BATCH_SIZE)\n",
    "#         .prefetch(AUTOTUNE)\n",
    "#     )\n",
    "\n",
    "# len(list(train_dataset.as_numpy_iterator())[0][0])\n",
    "# K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Log settings\n",
    "log_dir = \"./logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=0, write_graph=False, write_images=False)\n",
    "earlystop = keras.callbacks.EarlyStopping(\n",
    "           monitor='val_loss', \n",
    "           min_delta=0.0001, patience=10, \n",
    "           verbose=1, mode='auto')\n",
    "\n",
    "## Use a learning rate scheduler\n",
    "def scheduler(epoch):\n",
    "    if epoch < 10:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.001 * tf.math.exp(0.1 * (10 - epoch))\n",
    "lr_scheduler= tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "def train(model, trainset, validset, steps_per_epoch,\n",
    "          lr=0.01, \n",
    "          lr_scheduler=None, \n",
    "          earlystop=None, \n",
    "          optimizer='adam', \n",
    "          epochs=3\n",
    "         ):   \n",
    "    callbacks_list = [tensorboard]\n",
    "    if lr_scheduler:\n",
    "        callbacks_list.append(lr_scheduler)\n",
    "    else:\n",
    "        learning_rate = lr\n",
    "\n",
    "    if earlystop:\n",
    "        callbacks_list.append(earlystop)\n",
    "        \n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss=keras.losses.categorical_crossentropy,\n",
    "                  metrics=['categorical_accuracy'])\n",
    "\n",
    "    history = model.fit(trainset, \n",
    "                        epochs=epochs, \n",
    "                        callbacks=callbacks_list, \n",
    "                        validation_data=validset,\n",
    "                        steps_per_epoch=steps_per_epoch,\n",
    "                        verbose=True)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of adopting a fixed learning rate, we use a learning rate scheduler to adjust the learning rate. The learning rate decreases exponentially upon training epochs. Curve of learning rate scheduler is shown below.\n",
    "\n",
    "Also, we may need a earlystop callback function to mitigate the overfitting problem when some indicators are not increasing or decreasing in the training process. In this project we will use validation loss as the monitored indicator. The `patience` parameter of the earlystop function depends on the variance of the model. With `patience = n`, we finally get the `n`-th step after the model with smallest validation loss. According to our experiments, in our deep neural network model the validation loss does not actually decrease steadily in the most of time. We choose a relatively larger `patience`, say `patience=10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualisation\n",
    "def plot_history(history): \n",
    "    fig, ax1 = plt.subplots()\n",
    "    \n",
    "    ax1.plot(history.history['loss'], 'r', label=\"training loss ({:.6f})\".format(history.history['loss'][-1]))\n",
    "    ax1.plot(history.history['val_loss'], 'r--', label=\"validation loss ({:.6f})\".format(history.history['val_loss'][-1]))\n",
    "    ax1.grid(True)\n",
    "    ax1.set_xlabel('iteration')\n",
    "    ax1.legend(loc=\"best\", fontsize=9)    \n",
    "    ax1.set_ylabel('loss', color='r')\n",
    "    ax1.tick_params('y', colors='r')\n",
    "\n",
    "    if 'categorical_accuracy' in history.history:\n",
    "        ax2 = ax1.twinx()\n",
    "\n",
    "        ax2.plot(history.history['categorical_accuracy'], 'b', label=\"training acc ({:.4f})\".format(history.history['categorical_accuracy'][-1]))\n",
    "        ax2.plot(history.history['val_categorical_accuracy'], 'b--', label=\"validation acc ({:.4f})\".format(history.history['val_categorical_accuracy'][-1]))\n",
    "\n",
    "        ax2.legend(loc=\"best\", fontsize=9)\n",
    "        ax2.set_ylabel('acc', color='b')        \n",
    "        ax2.tick_params('y', colors='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.NN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we train serveral neural networks models including shallow neural network and well known deep neural networks in the area of image recognition/classification, with or without data augmentation.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) DenseNet121 with data augmentation\n",
    "\n",
    "In this section we try another deep network called DenseNet, proposed by Gao Huang et al[[2]](https://arxiv.org/pdf/1608.06993.pdf). DenseNet connects  each layer to every other layer in a feed-forward fashion to reuse the features. It has fewer parameters than ResNet but with same-level performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "def create_model_densenet121():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(DenseNet121(input_shape=(512, 512, 3),\n",
    "                          weights='imagenet',\n",
    "                          include_top=False))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "K.clear_session()\n",
    "BATCH_SIZE = 8  # \n",
    "STEPS_PER_EPOCH = train_labels.shape[0] // BATCH_SIZE\n",
    "trainset, validset, testset = build_dataset(batch_size=BATCH_SIZE, data_augment=data_augment)\n",
    "\n",
    "# Re-train the ResNet50 model with the same setup but with data augmentation\n",
    "model = create_model_densenet121()\n",
    "history = train(model, trainset, validset, \n",
    "                steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                lr_scheduler=lr_scheduler, \n",
    "                epochs=50\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_dnn = model.predict(testset, verbose=1)\n",
    "sub.loc[:, 'healthy':] = probs_dnn\n",
    "sub.to_csv('submission_DenseNet121_ww_augment.csv', index=False)\n",
    "sub.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of DenseNet121** This setup got public score 0.962 on kaggle Public LB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stop\n",
    "\n",
    "# Setup\n",
    "K.clear_session()\n",
    "BATCH_SIZE = 8  # \n",
    "STEPS_PER_EPOCH = train_labels.shape[0] // BATCH_SIZE\n",
    "trainset, validset, testset = build_dataset(batch_size=BATCH_SIZE, data_augment=data_augment)\n",
    "\n",
    "model = create_model_InceptionResNetV2()\n",
    "history = train(model, trainset, validset, \n",
    "                steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                lr_scheduler=lr_scheduler, \n",
    "                earlystop=earlystop,\n",
    "                epochs=100\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_dnn = model.predict(testset, verbose=1)\n",
    "sub.loc[:, 'healthy':] = probs_dnn\n",
    "sub.to_csv('submission_InceptionResNetV2_ww_augment_earlystop.csv', index=False)\n",
    "sub.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference \n",
    "\n",
    "[1]K. He, X. Zhang, S. Ren, and J. Sun, “[Deep Residual Learning for Image Recognition](http://arxiv.org/pdf/1512.03385),” arXiv:1512.03385 [cs], Dec. 2015, Accessed: May 04, 2020. [Online]. Available: http://arxiv.org/abs/1512.03385.\n",
    "\n",
    "\n",
    "[2]G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger, [“Densely Connected Convolutional Networks,”](https://arxiv.org/pdf/1608.06993.pdf) in 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, Jul. 2017, pp. 2261–2269, doi: 10.1109/CVPR.2017.243.\n",
    "\n",
    "[3]C. Szegedy, S. Ioffe, V. Vanhoucke, and A. Alemi, “[Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning](https://arxiv.org/pdf/1602.07261),” arXiv:1602.07261 [cs], Aug. 2016, Accessed: May 04, 2020. [Online]. Available: http://arxiv.org/abs/1602.07261.\n",
    "\n",
    "### Library docs, tutorials, manuals\n",
    "\n",
    "[TensorFlow: Data augmentation](https://www.tensorflow.org/tutorials/images/data_augmentation)\n",
    "\n",
    "[tf.data: Build TensorFlow input pipelines](https://www.tensorflow.org/guide/data)\n",
    "\n",
    "[TensorFlow: Load images](https://www.tensorflow.org/tutorials/load_data/images)\n",
    "\n",
    "[tensorflow.keras.applications](https://www.tensorflow.org/api_docs/python/tf/keras/applications)\n",
    "\n",
    "[Keras applications, model summaries, etc.](https://keras.io/applications/)\n",
    "\n",
    "[OpenCV background removal](https://www.kaggle.com/victorlouisdg/plant-pathology-opencv-background-removal/execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
